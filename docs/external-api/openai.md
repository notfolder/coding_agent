# OpenAI API 仕様

本ドキュメントは、OpenAI APIの概要と使用方法を日本語でまとめたものです。

---

## 1. 概要

### 1.1 OpenAI APIとは

OpenAI APIは、大規模言語モデル（LLM）を使用してプロンプトからテキストを生成するサービスです。ChatGPTと同様の機能をAPIとして提供しており、コード、数式、JSON形式のデータ、自然な文章など、様々な形式のテキストを生成できます。

### 1.2 主な機能

- **テキスト生成**: プロンプトに基づいてテキストを生成
- **構造化出力**: JSON形式での出力（Structured Outputs）
- **関数呼び出し**: ツール連携のための関数呼び出し機能
- **ストリーミング**: リアルタイムでの応答取得

---

## 2. モデル選択

### 2.1 利用可能なモデルタイプ

OpenAI APIでは複数のモデルタイプが提供されています。

#### 推論モデル（Reasoning Models）

内部で思考の連鎖を生成し、複雑なタスクやマルチステップの計画に優れています。GPTモデルと比較して処理が遅く、コストが高い傾向があります。

#### GPTモデル

高速で費用対効果が高く、高い知性を持ちますが、タスクの達成方法について明示的な指示が必要です。

#### 大規模・小規模モデル

大規模モデルはプロンプトの理解と問題解決に優れ、小規模モデル（miniやnano）は高速で低コストです。

### 2.2 推奨モデル

迷った場合は、gpt-4.1が知性、速度、コスト効率のバランスが取れているため推奨されます。

---

## 3. プロンプトエンジニアリング

### 3.1 概要

プロンプトエンジニアリングとは、モデルに対して効果的な指示を書くプロセスです。要求に合ったコンテンツを一貫して生成させるために重要な技術です。

### 3.2 ベストプラクティス

#### 本番環境での設定

- 特定のモデルスナップショット（例：gpt-4.1-2025-04-14）を固定して一貫した動作を確保する
- プロンプトの性能を測定するための評価（evals）を構築する

#### プロンプト構成

一般的に、developerメッセージには以下のセクションを含めます：

1. **Identity（アイデンティティ）**: アシスタントの目的、コミュニケーションスタイル、高レベルの目標を記述
2. **Instructions（指示）**: 応答生成に関するガイダンス、従うべきルール
3. **Examples（例）**: 入力例と期待される出力例
4. **Context（コンテキスト）**: 応答生成に必要な追加情報

---

## 4. メッセージロール

### 4.1 ロールの種類

OpenAI APIでは、異なる権限レベルを持つメッセージロールが提供されています。

#### developer（開発者）

アプリケーション開発者からの指示です。userメッセージよりも優先されます。

#### user（ユーザー）

エンドユーザーからの指示です。developerメッセージの後に優先されます。

#### assistant（アシスタント）

モデルによって生成されたメッセージです。

### 4.2 instructionsパラメータ

instructionsパラメータを使用すると、モデルに高レベルの指示を提供できます。inputパラメータのプロンプトよりも優先されます。

---

## 5. コンテキストウィンドウ

### 5.1 概要

モデルは生成リクエスト中に考慮できるデータ量に制限があります。このメモリ制限をコンテキストウィンドウと呼び、トークン単位で定義されます。

### 5.2 コンテキストサイズ

モデルによってコンテキストウィンドウサイズが異なります。新しいGPT-4.1モデルは最大100万トークンのコンテキストウィンドウを持ちます。具体的なサイズは各モデルのドキュメントを参照してください。

---

## 6. GPT-4.1モデルのプロンプティング

### 6.1 特徴

GPT-4.1などのGPTモデルは、タスク完了に必要なロジックとデータを明示的に提供する正確な指示から恩恵を受けます。

### 6.2 エージェントワークフローの構築

エージェントの機能を最大限に活用するため、以下の3種類のリマインダーをプロンプトに含めることを推奨します：

#### 永続性（Persistence）

ユーザーのクエリが完全に解決されるまで処理を継続し、問題が解決したと確信できるまでターンを終了しないよう指示します。

#### ツール呼び出し（Tool Calling）

ファイル内容やコードベース構造について不明な場合は、推測せずにツールを使用して情報を収集するよう指示します。

#### 計画（Planning）

各関数呼び出しの前に広範な計画を立て、前回の関数呼び出しの結果について広範に振り返るよう指示します。

### 6.3 長いコンテキストの使用

GPT-4.1は100万トークンの入力コンテキストウィンドウを持ち、構造化されたドキュメント解析、関連情報の選択、マルチホップ推論などの長いコンテキストタスクに有用です。

#### 区切り文字

コンテキストを区切るためにXMLタグや特定のフォーマットを使用することで、性能が向上します。JSONは長いコンテキストタスクでは性能が低下する傾向があります。

#### プロンプトの配置

長いコンテキストの使用では、重要な指示をプロンプトの上部と下部の両方に配置することが最適です。

---

## 7. 推論モデルのプロンプティング

### 7.1 GPTモデルとの違い

推論モデルはGPTモデルとは異なり、高レベルのガイダンスのみでより良い結果を生成します。

#### 推論モデル

シニアの同僚のように、目標を与えれば詳細を自分で解決できます。

#### GPTモデル

ジュニアの同僚のように、特定の出力を作成するための明示的な指示が最も効果的です。

---

## 8. APIエンドポイント

### 8.1 Responses API

テキスト生成の主要なAPIエンドポイントです。

#### 主要パラメータ

- **model**: 使用するモデル（必須）
- **input**: 入力プロンプトまたはメッセージ（必須）
- **instructions**: 高レベルの指示（オプション）
- **max_tokens**: 最大トークン数（オプション）

### 8.2 Chat Completions API

チャット形式での会話を継続するためのAPIです。

#### 主要パラメータ

- **model**: 使用するモデル（必須）
- **messages**: メッセージのリスト（必須）
- **functions**: 関数定義（オプション、関数呼び出し用）
- **function_call**: 関数呼び出しの制御（オプション）

---

## 9. 本プロジェクトでの使用

### 9.1 使用方法

本プロジェクトのOpenAIClientクラスでは、Chat Completions APIを使用してLLMとの対話を行います。

### 9.2 設定項目

config.yamlのllm.openaiセクションで以下を設定します：

- **api_key**: OpenAI APIキー（環境変数OPENAI_API_KEYを推奨）
- **base_url**: APIベースURL
- **model**: 使用するモデル
- **max_token**: 最大トークン数
- **context_length**: コンテキスト長

---

**参照元**: OpenAI公式ドキュメント（https://platform.openai.com/docs）
