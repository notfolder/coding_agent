mcp_servers:
  - mcp_server_name: "github"
    command:
      - "/app/github-mcp-server.cmd"
      - "stdio"
    env:
      GITHUB_TOOLSETS: "all"

  - mcp_server_name: "gitlab"
    command:
      - "npx"
      - "@zereight/mcp-gitlab"
      - "stdio"

  - mcp_server_name: "hashing"
    command:
      # - "conda"
      # - "run"
      # - "-n"
      # - "coding-agent"
      # - "hashing-mcp-server"
      # - "python"
      # - "-m"
      # - "hashing_mcp.cli"
      - "python"
      - "hashing.py"

llm:
  provider: "lmstudio"    # "ollama" | "openai"
  lmstudio:
    base_url: "host.docker.internal:1234"
    # base_url: "localhost:1234"
    context_length: 32768
    model: "qwen3-30b-a3b-mlx"
  ollama:
    endpoint: "http://host.docker.internal:11434"
    model: "qwen3-30b-a3b-mlx"
    max_token: 32768
  openai:
    api_key_env: "OPENAI_API_KEY"
    model: "gpt-4o"
    max_token: 32768
max_llm_process_num: 1000
github:
  owner:     "notfolder"
  bot_label: "coding agent"
  processing_label: "coding agent processing"
  done_label: "coding agent done"
  query: 'is:issue state:open archived:false author:@me sort:updated-desc sort:updated-desc'
gitlab:
  owner:     "notfolder"
  bot_label: "coding agent"
  processing_label: "coding agent processing"
  done_label: "coding agent done"
  project_id: "coding-agent-project"
  query: 'state=opened&scope=all&labels=coding agent'

scheduling:
  interval: 300  # ç§’
